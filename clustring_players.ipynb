{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "01e6ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a3b1a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ml_ready_players.csv')\n",
    "\n",
    "# Convert all bool columns to int automatically\n",
    "bool_cols = df.select_dtypes(include=['bool']).columns\n",
    "df[bool_cols] = df[bool_cols].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "538bfffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing position: Midfielder\n",
      "Number of clusters: 20\n",
      "Processing position: Forward\n",
      "Number of clusters: 20\n",
      "Processing position: Defender\n",
      "Number of clusters: 20\n",
      "Processing position: Goalkeeper\n",
      "Number of clusters: 20\n",
      "Processing position: Manager\n",
      "Number of clusters: 20\n",
      "✅ Clustering complete. Sample of updated DataFrame:\n",
      "  position_name  cluster\n",
      "0    Midfielder       11\n",
      "1       Forward       18\n",
      "2      Defender        9\n",
      "3       Forward        3\n",
      "4    Goalkeeper        9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "# Initialize cluster column\n",
    "df['cluster'] = -1  # Default value\n",
    "\n",
    "# Get unique positions excluding Manager\n",
    "positions = df['position_name'].unique()\n",
    "\n",
    "# Loop through each position group\n",
    "for pos in positions:\n",
    "    print(f\"Processing position: {pos}\")\n",
    "\n",
    "    # Filter data for current position\n",
    "    df_pos = df[df['position_name'] == pos].copy()\n",
    "\n",
    "    df_features = df_pos.drop(columns=['position_name'])\n",
    "\n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(df_features)\n",
    "\n",
    "\n",
    "    kmeans = KMeans(n_clusters=20, random_state=42, n_init='auto')\n",
    "    clusters = kmeans.fit_predict(X_scaled)\n",
    "        \n",
    "   \n",
    "    n_clusters = len(set(clusters)) - (1 if -1 in clusters else 0)\n",
    "    print(f'Number of clusters: {n_clusters}')\n",
    "\n",
    "\n",
    "    # Assign clusters back to main DataFrame\n",
    "    df.loc[df['position_name'] == pos, 'cluster'] = clusters\n",
    "    \n",
    "# Done\n",
    "print(\"✅ Clustering complete. Sample of updated DataFrame:\")\n",
    "print(df[['position_name', 'cluster']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "df3d9f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique clusters: 20\n",
      "Count of each cluster label:\n",
      "cluster\n",
      "4     89\n",
      "2     75\n",
      "11    66\n",
      "9     59\n",
      "1     51\n",
      "5     43\n",
      "13    40\n",
      "6     39\n",
      "0     37\n",
      "12    36\n",
      "17    34\n",
      "8     32\n",
      "15    31\n",
      "19    31\n",
      "10    29\n",
      "16    28\n",
      "14    26\n",
      "18    25\n",
      "3     23\n",
      "7     10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Assuming your dataframe is named df and cluster column is 'clusters'\n",
    "unique_clusters = df['cluster'].nunique()\n",
    "print(f\"Number of unique clusters: {unique_clusters}\")\n",
    "\n",
    "cluster_counts = df['cluster'].value_counts()\n",
    "print(\"Count of each cluster label:\")\n",
    "print(cluster_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "19c7a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('full_data.csv')\n",
    "df2['cluster'] = df['cluster']\n",
    "df2.to_csv('clustered_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c87c47f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
